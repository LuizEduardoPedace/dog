# Introdu√ß√£o üêï

Mais do que nunca, o melhor amigo do homem faz juz ao seu nome. Em grandes capitais como S√£o Paulo, √© dif√≠cil observar algum momento do dia em que n√£o h√° pessoas passando o tempo com seus c√£es, o que por diversas vezes, √© comparado ao relacionamento de um filho ou parente pr√≥ximo.

No entanto, ainda vemos muitos c√£es nas ruas e as taxas de abandono de animais continuam elevadas. Escolher um *pet* deve estar atrelado √†s suas escolhas pessoas e ao seu estilo de vida, fatores como dinheiro, tra√ßo de temperamento do animal e tamanho devem ser levados em conta na hora de escolher o seu companheiro.

Por esse motivo, a partir de um *dataset* criei um ***dashboard*** com filtros relevantes para te ajudar a escolher qual a **ra√ßa de c√£o** üê∂ mais compat√≠vel com seu **perfil**! Al√©m disso, realizei uma an√°lise aprofundada utilizando algumas t√©cnicas de **estat√≠stica** para encontrar *insights* interessantes no que diz respeito ao pre√ßo da ra√ßa e ao tra√ßo de temperamento.


# Ferramentas Utilizadas üõ†Ô∏è

- **Excel:** O software utilizado para importa√ß√£o do *dataset* e realiza√ß√£o do EDA (*Exploratory Data Analysis*);

- **Power Query:** O software utilizado para a extra√ß√£o, transforma√ß√£o e carregamentos dos dados;

- **PowerBI:** O software utilizado para construir um *dashboard* com filtros interativos;

- **Power Pivot:** O ambiente utilizado para criar rela√ß√µes entre as tabelas e medidas √∫teis;

- **Visual Studio Code:** O ambiente interativo utilizado para criar os c√≥digos com facilidade e rapidez;

- **Python:** A linguagem de programa√ß√£o utilizada para realizar a an√°lise a partir da manipula√ß√£o de dados, constru√ß√£o de visualiza√ß√µes e usufruo de t√©cnicas estat√≠sticas. Foram utilizadas bibliotecas como: numpy, pandas, seaborn, matplotlib, scipy;

- **Jupyter Notebook:** Formato de arquivo utilizado com a linguagem de programa√ß√£o python para organiza√ß√£o do c√≥digo;

- **Git & GitHub:** O software utilizado para monitorar as modifica√ß√µes feitas no projeto no decorrer do desenvolvimento, e public√°-lo em um reposit√≥rio de f√°cil acesso aos dados utilizados, os c√≥digos constru√≠dos e ao relat√≥rio final.


# *Dataset* üóÇÔ∏è

O *dataset* escolhido est√° no reposit√≥rio como [dog_breed_characteristics.csv](/dog_breed_characteristics.csv). Ele cont√©m as seguintes colunas:

- üê∂ **Nome da Ra√ßa**

- üí≤ **Pre√ßo m√©dio**

- üêæ **Grupo**

- ‚öñÔ∏è **Peso**

- ‚ö†Ô∏è **N√≠vel de vigil√¢ncia**

- üëë **Popularidade**

- üé≠ **Temperamento**

As demais colunas contidas no *dataset* ser√£o removidas no processo de *ETL (Extract, Transform and Loading)* dos dados.


# Extra√ß√£o, Transforma√ß√£o e Carregamento dos Dados ‚õèÔ∏è

O *dataset* original cont√©m muitos erros. H√° colunas cuja maioria dos dados √© nula, erros de digita√ß√£o, linhas duplicadas, entre outras coisas. √â de suma import√¢ncia explorar os dados inicialmente para retirarmos informa√ß√µes incoerentes com o todo. Para esta etapa, utilizei o **Excel**, **Power Query** e o **Python**.

## üì§ **Extra√ß√£o**

O *dataset* original ```dog_breed_characteristics.csv``` foi carregado no Excel, onde pude criar uma tabela para incorporar ao Power Query e realizar as modifica√ß√µes necess√°rias. Foram criadas duas ***Queries***:

- üê∂ **dog_characteristics**

![](/assets/ETL/dog_characteristics_extract.PNG)

- üçÄ **dog_trait** 

![](/assets/ETL/dog_trait_extract.PNG)

A primeira tabela cont√©m as caracter√≠sticas gerais de cada ra√ßa como pre√ßo, peso, grupo etc. A segunda tabela possui a lista de tra√ßos de temperamento para cara ra√ßa de c√£o.

## üîÑ Transforma√ß√£o

Foi necess√°rios corrigir os erros de dados citados em cada uma das tabelas criadas. 

- üê∂ **dog_characteristics**

Removi colunas in√∫teis, alterei o tipo de dado, corrigi dados duplicados, filtrei apenas as informa√ß√µes relevantes, renomiei e reordenei colunas, entre outras coisas.

![](/assets/ETL/dog_characteristics_transform.PNG)

- üçÄ **dog_trait** 

Foi necess√°rio separar cada um dos tra√ßos de temperamento para cada uma das ra√ßas de modo que fosse poss√≠vel corresponder esta *querie* com a primeira.

![](/assets/ETL/dog_trait_transform.PNG)

O documento de Excel com as *queries* e transforma√ß√µes realizadas pode ser encontrado em [dog_breed_characteristics.xlsx](/dog_breed_characteristics.xlsx).

## üîó Carregamento

De posse dos dados corrigidos, criei um arquivo *.csv* para cada *querie* (```dog_characteristics.csv``` e ```dog_trait.csv```), a fim de incporporar ao *jupyter notebook* para realizar a an√°lise subsequente.

```python
import pandas as pd

# dog_characteristics
df_1 = pd.read_csv('dog_characteristics.csv', delimiter=';')

# dog_trait
df_2 = pd.read_csv('dog_trait.csv', delimiter=';')
```


# Dashboard üì∂

Antes da an√°lise, confira o *dashboard* que eu criei:

üìå [Dashboard](https://app.powerbi.com/view?r=eyJrIjoiZTdjM2U1OTUtOWUyOC00MjY0LWEzNzktN2Q3ZWZmZGNmMTFmIiwidCI6IjdlOTNlMjg2LWIyOWEtNDQ1NC1hNDFhLWU4NDE5ZWM5ZGViNSJ9)

![](/assets/dashboard/dashboard_gif.gif)

Voc√™ poder√° escolher diversos filtros e ele retornar√° a ra√ßa de c√£o que mais atende ao seu perfil.
Voc√™ encontrar√° os seguintes **filtros**:

- üí≤ **Pre√ßo m√©dio**

- üêæ **Grupo**

- ‚öñÔ∏è **Peso**

- ‚ö†Ô∏è **N√≠vel de vigil√¢ncia**

- üé≠ **Temperamento**

Para constru√≠-lo, importei o Power Query desenvolvido anteriormente no **Power BI**.  Foi necess√°rio a cria√ß√£o de uma nota tabela para filtrarmos as ra√ßas por grupo:

![](/assets/dashboard/dog_group_table.PNG)

Posteriormente, como inserimos filtros a partir de tr√™s tabelas diferentes, foi necess√°rio utilizar o **Power Pivot** para criar rela√ß√µes entre as tabelas a partir do **nome das ra√ßas**:

![](/assets/dashboard/power_pivot_relationships.PNG)

Com isso, estamos prontos para a cria√ß√£o do *dashboard*. Ao lado esquerdo encontra-se uma lista das ra√ßas de c√£es que **atendem aos requisitos** e seu respectivo **pre√ßo**:

![](/assets/dashboard/list_of_breeds.PNG)

No canto superior encontra-se a ra√ßa de c√£o **mais cara** que atende aos requisitos e seu respectivo pre√ßo. Necessitou-se a cria√ß√£o de uma medida para encontrarmos o nome:

```dax
top_breed = MAXX(TOPN(1,dog_characteristics,dog_characteristics[Price],DESC),dog_characteristics[BreedName])
```

![](/assets/dashboard/expensive_breed.PNG)


# An√°lise üìä

A an√°lise feita est√° em ```main.ipynb```, nele est√° contido um *jupyter notebook* detalhado com anota√ß√µes, os c√≥digos utilizados, visualiza√ß√µes do relat√≥rio e equa√ß√µes.

Vamos come√ßar a an√°lise estudando como o pre√ßo m√©dio est√° distribu√≠do no *dataset*. Para isso, utilizaremos estat√≠stica descritiva:

```python
df_1['Price'].describe().round(2)
```

| Estat√≠stica   | Valor      |
|---------------|------------|
| Mediana       | $ 900.00   |
| M√©dia         | $ 1045.04  |
| Desvio Padr√£o | $ 518.73   |
| M√≠nimo        | $ 350.00   |
| M√°ximo        | $ 3000.00  |
| 1¬∞ quartil    | $ 700.00   |
| 2¬∞ quartil    | $ 900.00   |
| 3¬∞ quartil    | $ 1350.00  |
| Vari√¢ncia     | $ 269083.19|

*Tabela com algumas estat√≠sticas descritivas para os pre√ßos das ra√ßas de c√£es.*

Note como a faixa de pre√ßo dos c√£es pode variar bastante, chegando a pre√ßos de **$3000.00**! A m√©dia dos pre√ßos √© elevada considerando-se o sal√°rio m√≠nimo e a vari√¢ncia dos dados √© descomunal. Vamos entender depois o motivo da vari√¢ncia ser t√£oi elevada com testes equivalentes ao **ANOVA**.

Podemos usufruir do boxplot para obter informa√ß√£o visual de como os dados est√£o distribu√≠dos:

![](/assets/analysis/boxplot_price_outliers.png)

*Boxplot dos pre√ßos para as ra√ßas de c√£es.*

Note a presen√ßa de ***outliers***, o que explica o valor da m√©dia ser maior do que a mediana. Al√©m do mais, **50%** dos dados est√£o entre (**\$700.00**, **\$1350.00**), a partir da√≠ os pre√ßos come√ßam a dar grandes saltos como √© poss√≠vel ver pela largura da parte de cima do boxplot.

Quais ra√ßas s√£o respons√°veis pelos *outliers*? Sabemos que o piso superior e inferior s√£o calculados da seguinte maneira:

$$\text{Lower Outlier} = Q_1 - (1.5 \cdot \text{IQR})$$
$$\text{Higher Outlier} = Q_3 + (1.5 \cdot \text{IQR})$$
$$\text{IQR} = Q_3 - Q_1$$

Com isso, podemos calcul√°-los diretamente no python:

```python
Q1 = df_1['Price'].quantile(.25) # Primeiro Quartil
Q3 = df_1['Price'].quantile(.75) # Terceiro Quartil
IQR = Q3 - Q1 #Interquartil
low_out = Q1 - (1.5 * IQR) # Piso Inferior
hig_out = Q3 + (1.5 * IQR) # Piso Superior

# Tabela de Outliers
outliers = df_1[df_1['Price'] > hig_out].sort_values('Price', ascending=1)
``` 

| Nome da Ra√ßa               | Pre√ßo     |
|----------------------------|-----------|
| French Bulldog             | $ 3000.00 |
| Kai Dog                    | $ 3000.00 |
| Tibetan Mastiff            | $ 3000.00 |
| Pumi                       | $ 2750.00 |
| Coton de Tulear            | $ 2700.00 |
| Portuguese Water Dog       | $ 2650.00 |
| Sussex Spaniel             | $ 2500.00 |

*Tabela com os outliers e seus respectivos pre√ßos.*

Vemos que ra√ßas mundialmente conhecidas como **Buldogue Franc√™s** e **Mastim Tibetano** lideram o pre√ßo das ra√ßas de c√£es. Podemos nos perguntar qual o tra√ßo de temperamento mais comum dentre esses *outliers*.

```python
outliers_trait = df_2[df_2['BreedName'].isin(outliers['BreedName'])].groupby('Trait').count().sort_values('BreedName', ascending=0)[0:10]
```

![](/assets/analysis/hbar_outliers_count_trait.png)

*Gr√°fico de barras da contagem de tra√ßos para os outliers.*

Tra√ßos como **inteligente** e **vivaz** s√£o os mais comuns dentre as ra√ßas de c√£es mais caras. Mais adiante vamos obter o pre√ßo m√©dio para cada tra√ßo de temperamento e averiguaremos se estes mesmos tra√ßos est√£o no Top 10.

Vamos agora retirar os *outliers* do *dataset* para analisarmos tend√™ncias e entendermos os dados com mais afinco.

```python
df_out = df_1[df_1['Price'].isna() == False].drop(index=outliers.index)
df_out['Price'].describe().round(2)
```

| Estat√≠stica   | Valor       |
|---------------|-------------|
| Mediana       | $ 900.00    |
| M√©dia         | $ 992.77    |
| Desvio Padr√£o | $ 425.69    |
| M√≠nimo        | $ 350.00    |
| M√°ximo        | $ 2250.00   |
| 1¬∞ quartil    | $ 700.00    |
| 2¬∞ quartil    | $ 900.00    |
| 3¬∞ quartil    | $ 1275.00   |
| Vari√¢ncia     | $ 181208.13 |

*Tabela com algumas estat√≠sticas descritivas para os pre√ßos das ra√ßas de c√£es do dataset sem os outliers.*

A m√©dia diminui e se torna mais pr√≥xima da mediana como era de se esperar. O valor m√°ximo agora √© de **\$2250.00**, note que a vari√¢ncia continua bastante elevada, iremos tentar entender o motivo disso.

![](/assets/analysis/histogram_price.png)

*Histograma do pre√ßo das ra√ßas de c√£es sem os outliers.*

Existe uma predomin√¢ncia dos pre√ßos entre **\$700.00** e **\$1100.00** como √© poss√≠vel ver pelo pico do histograma. Note tamb√©m que h√° um ac√∫mulo de valores entre **\$350.00** e **\$600.00**. Podemos nos pergunta se os dados acima s√£o bem descritos por uma distribui√ß√£o normal, para isso, podemos efetuar uma **an√°lise visual** bem como um teste de estat√≠stica.

![](/assets/analysis/kde_price.png)

*Kernel Density Estimation para o pre√ßo das ra√ßas de c√£es.*

Visualmente percebemos que n√£o se aproxima de uma distribui√ß√£o normal. Vamos utilizar o ***Quantile-Quantile plot***:

```python
import scipy.stats as stats

stats.probplot(df_out['Price'], dist='norm', plot=plt)
```

![](/assets/analysis/q_q_plot_price.png)

*Quantile-Quantile plot para o pre√ßo das ra√ßas de c√£es.*

Pela visualiza√ß√£o *quartil-quartil* os dados definitivamente n√£o s√£o bem descritos por uma distribui√ß√£o normal. Por√©m, podemos ainda utilizar o **Teste de Anderson-Darling**:

```python
stats.anderson(df_out['Price'])
```

| Estat√≠stica                 | Valor |
|-----------------------------|-------|
| Anderson-Darling            | 4.02  |
| Valor cr√≠tico ($\alpha=.05$)| 0.774 |

*Tabela com o Teste de Anderson-Darling e seus respectivos resultados.*

Para um **valor de signific√¢ncia** de $\alpha=.05$, n√≥s definitivamente podemos **descartar a hip√≥tese nula** e portanto os dados **n√£o s√£o bem descritos por uma distribui√ß√£o normal**.

Agora que testamos a normalidade, vamos utilizar testes **n√£o-param√©tricos** para **estudar a vari√¢ncia** e realizar **testes de hip√≥tese**.

## An√°lise por Grupo üêæ

Como vimos, a vari√¢ncia dos dados √© elevada, vamos separar as ra√ßas de c√£es por **Grupo** e estudar se eles est√£o de alguma forma atrelados √° essa dispers√£o.

```python
df_group = df_out[['BreedName','Group1','Group2','Price']].copy()
df_group['Group'] = df_out['Group1'] + ',' + df_out['Group2']
df_group['Group'] = df_group['Group'].str.split(',')
df_group.drop(columns=['Group1','Group2'], inplace=True)
df_group = df_group.explode('Group', ignore_index=True)
```

![](/assets/analysis/boxplot_group.png)

*Boxplot do pre√ßo das ra√ßas por Grupo.*

Vemos que grupos como **Guardi√£o** e **Trabalhador** possuem uma m√©dia de pre√ßo maior do que a m√©dia, enquanto **C√£o Farejador** est√° bem abaixo. Visualmente podemos explicar a dispers√£o dos dados devido √† varia√ß√£o de pre√ßo entre os grupos, no entanto, podemos efetuar um teste estat√≠stico para quantizar essa varia√ß√£o. Porquanto, utilizaremos o **Teste de Kruskal-Wallis** para esta an√°lise.

```python
values = df_group[df_group['Group'].isna() == False]['Group'].unique()
data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13 = [df_out[df_group['Group'] == g]['Price'] for g in values]
stats.kruskal(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13)
```

| Estat√≠stica           | Valor |
|-----------------------|-------|
| Kruskal-Wallis        | 18.00 |
| valor-p               | 0.11  |

*Tabela com o Teste de Kruskal-Wallis e seus respectivos resultados.*

Para um **valor de signific√¢ncia** de $\alpha=.05$ n√≥s **n√£o** podemos descartar a **hip√≥tese nula**. Pela visualiza√ß√£o, o grupo C√£o Farejador se destaca dentre os demais devido ao seu pre√ßo m√©dio ser bem inferior √† media total. Vamos estudar esse grupo com mais afinco.

```python
Scenthound = df_group[df_group['Group'] == 'Scenthound']
```

Iniciaremos fazendo uma an√°lise descritiva.

| Estat√≠stica    | Valor       |
|----------------|-------------|
| Mediana        | $ 500.00    |
| M√©dia          | $ 663.00    |
| Desvio Padr√£o  | $ 412.00    |
| M√≠nimo         | $ 350.00    |
| M√°ximo         | $ 1900.00   |
| 1¬∞ quartil     | $ 400.00    |
| 2¬∞ quartil     | $ 500.00    |
| 3¬∞ quartil     | $ 675.00    |
| Vari√¢ncia      | $ 169956.14 |

*Tabela com algumas estat√≠sticas descritivas para os pre√ßos do grupo Scenthound.*

Percebemos que os valores para a m√©dia e mediana s√£o bem inferiores com rela√ß√£o ao *dataset* original. A m√©dia est√° acima da mediana, o que pode demonstrar a exist√™ncia de *outliers* e a vari√¢ncia permanece elevada dentro do pr√≥prio grupo.

![](/assets/analysis/boxplot_scenthound.png)

*Boxplot da faixa de pre√ßo do grupo Scenthound.*

Como analisado anteriormente, h√° a exist√™ncia de *outliers*, enquanto que a m√©dia est√° √† parte da maior parte dos dados, revelando que algumas ra√ßas est√£o com um pre√ßo muito acima da maioria. Por esse motivo, vamos encontrar os *outliers* e separ√°-los dos demais dados do grupo.

| Nome da Ra√ßa                    | Pre√ßo   |
|---------------------------------|---------|
| Irish Wolfhound                 | $ 1900.0|
| Petit Basset Griffon Vendeen    | $ 1400.0|
| English Coonhound               | $ 1100.0|

*Tabela com os outliers do grupo Scenthound e seus respectivos pre√ßos.*

√â poss√≠vel ver qeu os *outliers* est√£o muito acima da m√©dia do grupo. Enquanto 50% dos valores est√£o entre **\$400.00** e **\$675.00**, eles est√£o com pre√ßos maiores do que o dobro. Retirando-se os *outliers*, os dados **n√£o** s√£o bem descritos por uma **distribui√ß√£o normal**, os testes feitos foram os mesmos feitos anteriormente e se encontram no [*jupyter notebook*](/main.ipynb).

Deste modo, vamos utilizar um **teste de hip√≥tese** n√£o-param√©trico para averiguar se com esses dados podemos inferir que a m√©dia do grupo √© inferior √† media total. Utilizaremos o **Teste de Wilcoxon**:

```python
stats.wilcoxon(Scenthound_data['Price'] - df_out['Price'].mean())
```

| Estat√≠stica           | Valor   |
|-----------------------|---------|
| Wilcoxon              | 1.00    |
| valor-p               | 6.10e-05|

*Tabela com o Teste de Wilcoxon e seus respectivos resultados.*

Indubitavelmente podemos **descartar** a **hip√≥tese nula** e inferir que a m√©dia de pre√ßo do grupo Scenthound √© **inferior √† media total**.

## An√°lise por N√≠vel de Vigil√¢ncia ‚ö†Ô∏è

Vamos agora separar os grupos por **n√≠vel de vigil√¢ncia** das ra√ßas. Neste *dataset* a vigil√¢ncia √© uma **vari√°vel categ√≥rica** de 1 a 6.

![](/assets/analysis/boxplot_watchdog.png)

*Boxplot do pre√ßo das ra√ßas por N√≠vel de Vigil√¢ncia.*

Pela visualiza√ß√£o, a m√©dia de pre√ßo n√£o varia tanto como na separa√ß√£o por Grupo. Vamos efetuar o **Teste de Kruskal-Wallis** para analisar se podemos inferir que essa separa√ß√£o est√° atrelada √† dispers√£o dos dados.:

| Estat√≠stica           | Valor |
|-----------------------|-------|
| Kruskal-Wallis        | 12.82 |
| valor-p               | 0.02  |

*Tabela com o Teste de Kruskal-Wallis e seus respectivos resultados.*

Para um **valor de signific√¢ncia** de $\alpha=.05$ podemos **descartar** a **hip√≥tese nula** e inferir que as m√©dias de cada grupo diferem. Notemos ainda que pode existir uma certa **correla√ß√£o** entre a m√©dia de pre√ßos e o n√≠vel de vigil√¢ncia:

![](/assets/analysis/scatter_price_x_watchdog.png)

*Gr√°fico do Pre√ßo M√©dio em fun√ß√£o no N√≠vel de Vigil√¢ncia.*

Ao considerarmos a m√©dia de pre√ßo em fun√ß√£o do n√≠vel de vigil√¢ncia e testar a normalidade dos dados, podemos inferir que eles s√£o **bem descritos** por uma **distribui√ß√£o normal**. Os testes feitos s√£o os mesmos e est√£o no [*jupyter notebook*](/main.ipynb). Com isso, podemos utilizar a **Correla√ß√£o de Pearson** (ao considerarmos o n√≠vel de vigil√¢ncia uma **vari√°vel m√©trica**):

```python
# Dados
watchdog = df_out.groupby('Watchdog')['Price'].mean().index.tolist()
watchdog_avg = df_out.groupby('Watchdog')['Price'].mean().values.tolist()
# Teste
stats.pearsonr(watchdog, watchdog_avg)
```

| Estat√≠stica           | Valor |
|-----------------------|-------|
| Pearson r             | 0.77  |
| valor-p               | 0.07  |

*Tabela com a Correla√ß√£o de Pearson e seus respectivos resultados.*

Por mais que a correla√ß√£o $r$ de Pearson tenha sido elevada, devido √† **falta de dados**, **n√£o** podemos descartar a **hip√≥tese nula** e inferir que existe uma correla√ß√£o entre as vari√°veis.

No *dataset* possu√≠mos as vari√°veis m√©tricas ‚öñÔ∏è **Peso** e üëë **Popularidade**, vamos testar a correla√ß√£o entre estas vari√°veis e o pre√ßo:

![](/assets/analysis/heatmap_corr.png)

*Mapa de calor das correla√ß√µes entre Pre√ßo, Peso e Popularidade .*

Pelo mapa de calor acima vemos que n√£o h√° nenhuma correla√ß√£o significante entre as tr√™s vari√°veis.


## Tra√ßo de Temperamento üé≠

Por fim, vamos obter alguns *insights* a partir da an√°lise dos tra√ßos de temperamento. Primeiramente, vamos entender como estes est√£o distribu√≠dos:

![](/assets/analysis/pie_top10_traits.png)

*Gr√°fico de pizza para os 10 tra√ßos mais comuns.*

Vemos que o tra√ßo **inteligente** √© o mais comum, o que demonstra n√£o estar atrelado necessariamente √†s ra√ßas caninas mais caras como vimos anteriormente. Vamos averiguar isto mais a fundo obtendo o pre√ßo m√©dio atrelado a cada tra√ßo:

```python
trait_price = {}
for t in df_2['Trait'].unique().tolist():
    trait_price[t] = df_1[df_1['Temperament'].str.contains(t, case=False)]['Price'].mean()
trait_price = pd.DataFrame.from_dict(trait_price, orient='index')
trait_price = trait_price.rename(columns={0: 'Price'})
trait_price.index.name = 'Trait'
trait_price.reset_index(inplace=True)

top_traits = trait_price.sort_values('Price',ascending=0)[0:10].round(2)
```

![](/assets/analysis/hbar_top10_trait_price.png)
*Gr√°fico de barras para os 10 tra√ßos de temperamento mais caros*

Tra√ßos como **Briguento** e **Impetuoso** est√£o entre os mais caros custando acima de **\$2500.00**! Os tra√ßos inteligente e vivaz vistos anteriormente nos outliers n√£o est√£o presentes.

Vamos agora visualizar o boxplot para os 15 tra√ßos mais comuns e testar se isso explica a dispers√£o de vari√¢ncia encontrada nos dados.

![](/assets/analysis/boxplot_trait.png)

*Boxplot do pre√ßo em fun√ß√£o dos 15 tra√ßos mais comuns.*

Vemos que a m√©dia de pre√ßo dos tra√ßos n√£o dista de forma sifnificante, ao utilizarmos o Teste de Kruskal-Wallis obtivemos que:

| Estat√≠stica           | Valor |
|-----------------------|-------|
| Kruskal-Wallis        | 13.47 |
| valor-p               | 0.49  |

*Tabela com o Teste de Kruskal-Wallis e seus respectivos resultados.*

Com isso, **n√£o** podemos descartar a **hip√≥tese nula** e isso n√£o explica a dispers√£o encontrada.

# Conclus√£o üí°

Primeiramente, realizamos uma **an√°lise descritiva** dos pre√ßos e estudamos seus ***outliers***, procuramos obter alguma rela√ß√£o entre seus pre√ßos elevados e tra√ßos comportamentais. Vimos que **inteligente** e **vivaz** s√£o os mais comuns entre as ra√ßas mais caras. 

Com o usufruo de boxplots e a partir do valor da vari√¢ncia, averiguamos que faixa de pre√ßo pode variar bastante dentro do *dataset*, ent√£o procuramos entender de onde se origina tal dispers√£o, para isso, foi utilizado a contraparte **n√£o-param√©trica** do ANOVA (**Kruskal-Wallis**). Separamos os dados por üêæ **Grupo**, ‚ö†Ô∏è **N√≠vel de Vigil√¢ncia** e üé≠ **Tra√ßo de Temperamento**. Obtivemos que o N√≠vel de Vigil√¢ncia e Grupo explicam melhor a origem da dispers√£o. Encontramos tamb√©m uma **correla√ß√£o** forte entre pre√ßo e vigil√¢ncia, mas devido √† falta de dados n√£o podemos inferir a partir de um **valor de signific√¢ncia** de $\alpha=.05$.

O grupo **C√£o Farejador** possui uma m√©dia de pre√ßo bem abaixo da m√©dia, com exce√ß√£o de poucas ra√ßas, a partir do **teste de hip√≥tese n√£o-param√©trico Wilcoxon** obtivemos um valor-p indubitavelmente menor que o valor de signific√¢ncia. Demonstrando que o grupo de fato possui uma m√©dia de pre√ßo inferior aos demais.

Por fim, estudamos a distribui√ß√£o de tra√ßos de temperamento, obtivemos que **Briguento** e **Impetuoso** possuem os maiores pre√ßos m√©dios, com valores acima **\$2500.00**!